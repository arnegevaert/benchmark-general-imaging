{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attribench.util import visualize_attributions\n",
    "from util.datasets import unnormalize\n",
    "from attribench.data import (\n",
    "    AttributionsDataset,\n",
    "    HDF5Dataset,\n",
    "    GroupedAttributionsDataset,\n",
    ")\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_path = \"../out/2023_08_22/\"\n",
    "dataset_name = \"ImageNet\"\n",
    "idx = 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = os.path.join(res_path, dataset_name)\n",
    "samples_dataset = HDF5Dataset(path=os.path.join(ds_path, \"samples.h5\"))\n",
    "attrs_dataset = GroupedAttributionsDataset(AttributionsDataset(\n",
    "    samples=samples_dataset, path=os.path.join(ds_path, \"attributions.h5\")\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, image, label, attrs = attrs_dataset[idx]\n",
    "image = torch.tensor(image).unsqueeze(0)\n",
    "image = unnormalize(image, dataset_name)\n",
    "image = image.squeeze(0).permute(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visualize_attributions(\n",
    "    attributions=attrs,\n",
    "    image=image,\n",
    "    overlay=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "from collections import defaultdict\n",
    "\n",
    "for ds_name in [\"MNIST\", \"FashionMNIST\", \"SVHN\", \"CIFAR10\", \"CIFAR100\", \"ImageNet\", \"Places365\", \"Caltech256\"]:\n",
    "    ds_path = os.path.join(res_path, ds_name)\n",
    "    samples_dataset = HDF5Dataset(path=os.path.join(ds_path, \"samples.h5\"))\n",
    "    attrs_dataset = GroupedAttributionsDataset(AttributionsDataset(\n",
    "        samples=samples_dataset, path=os.path.join(ds_path, \"attributions.h5\")\n",
    "    ))\n",
    "    has_nans = defaultdict(lambda: False)\n",
    "\n",
    "    for i in trange(256):\n",
    "        idx, image, label, attrs = attrs_dataset[i]\n",
    "        for method_name in attrs:\n",
    "            has_nans[method_name] = has_nans[method_name] or torch.isnan(attrs[method_name]).any().item()\n",
    "\n",
    "    for key in has_nans:\n",
    "        if has_nans[key]:\n",
    "            print(f\"{ds_name}: {key} has nans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmark-general-imaging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
